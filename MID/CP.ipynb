{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b468fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generating 500 random data points.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 500\n",
    "X = np.random.randn(N, 2) * 2\n",
    "radii = np.sum(X**2, axis=1)\n",
    "Y = np.zeros((N, 3))\n",
    "for i in range(N):\n",
    "    if radii[i] < 2:\n",
    "        Y[i, 0] = 1\n",
    "    elif radii[i] < 6:\n",
    "        Y[i, 1] = 1\n",
    "    else:\n",
    "        Y[i, 2] = 1\n",
    "\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0) + 1e-9\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "# Code for 3-Layer NN starts here below.\n",
    "\n",
    "def relu(x): return np.maximum(0, x)\n",
    "def relu_deriv(x): return (x > 0).astype(float)\n",
    "def softmax(x):\n",
    "    ex = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return ex / np.sum(ex, axis=1, keepdims=True)\n",
    "def cross_entropy(pred, true):\n",
    "    return -np.mean(np.sum(true * np.log(pred + 1e-12), axis=1))\n",
    "\n",
    "def xavier_init(fan_in, fan_out):\n",
    "    limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return np.random.uniform(-limit, limit, size=(fan_in, fan_out))\n",
    "\n",
    "class ThreeLayerNN:\n",
    "    def __init__(self, input_dim=2, h1=32, h2=16, output_dim=3, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.W1 = xavier_init(input_dim, h1)\n",
    "        self.b1 = np.zeros((1, h1))\n",
    "        self.W2 = xavier_init(h1, h2)\n",
    "        self.b2 = np.zeros((1, h2))\n",
    "        self.W3 = xavier_init(h2, output_dim)\n",
    "        self.b3 = np.zeros((1, output_dim))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = X.dot(self.W1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = self.a1.dot(self.W2) + self.b2\n",
    "        self.a2 = relu(self.z2)\n",
    "        self.z3 = self.a2.dot(self.W3) + self.b3\n",
    "        self.out = softmax(self.z3)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, X, Y):\n",
    "        N = X.shape[0]\n",
    "        dZ3 = (self.out - Y) / N\n",
    "        dW3 = self.a2.T.dot(dZ3)\n",
    "        db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
    "\n",
    "        dA2 = dZ3.dot(self.W3.T)\n",
    "        dZ2 = dA2 * relu_deriv(self.z2)\n",
    "        dW2 = self.a1.T.dot(dZ2)\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "        dA1 = dZ2.dot(self.W2.T)\n",
    "        dZ1 = dA1 * relu_deriv(self.z1)\n",
    "        dW1 = X.T.dot(dZ1)\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "        self.W3 -= self.lr * dW3\n",
    "        self.b3 -= self.lr * db3\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def train_epoch(self, X, Y, batch_size=64):\n",
    "        idx = np.random.permutation(len(X))\n",
    "        Xs, Ys = X[idx], Y[idx]\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            xb = Xs[start:start+batch_size]\n",
    "            yb = Ys[start:start+batch_size]\n",
    "            self.forward(xb)\n",
    "            self.backward(xb, yb)\n",
    "\n",
    "model = ThreeLayerNN(lr=0.01)\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "losses = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train_epoch(X, Y, batch_size=batch_size)\n",
    "    pred = model.forward(X)\n",
    "    loss = cross_entropy(pred, Y)\n",
    "    losses.append(loss)\n",
    "    if ep % 100 == 0:\n",
    "        print(f\"Epoch {ep}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Plotting the Loss Curve Below\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
